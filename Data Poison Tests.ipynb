{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/dominiccroce/anaconda3/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n",
      "/Users/dominiccroce/anaconda3/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load(\"data/ship_bike_x_train.npy\").astype('float32')\n",
    "y_train = np.load(\"data/ship_bike_y_train.npy\").astype('float32')\n",
    "\n",
    "x_test = np.load(\"data/ship_bike_x_test.npy\").astype('float32')\n",
    "y_test = np.load(\"data/ship_bike_y_test.npy\").astype('float32')\n",
    "\n",
    "ship_bike_dataset = (x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(386, 256, 256, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "from squeeze_net_keras_wdropout import SqueezeNetBinaryKeras\n",
    "\n",
    "model = SqueezeNetBinaryKeras(input_shape=(256, 256, 3), drop_p = 0.6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import cifar10\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "K.set_learning_phase(1)\n",
    "\n",
    "from utils.influence_helpers import influence_binary_top_model_explicit, data_poisoning_attack, compute_bottleneck_features\n",
    "from utils.influence_helpers import grad_influence_wrt_input, construct_top_model, train_top_model, sync_top_model_to_full_model\n",
    "\n",
    "from simple_kerasinstance import SimpleCNN\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"TkAgg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "class InfluencePoisoner:\n",
    "\n",
    "    def __init__(self,\n",
    "                 dataset,\n",
    "                 model,\n",
    "                 model_weights_path = None,\n",
    "                 bottleneck_features_path = None,\n",
    "                 reduced_train_size = None,\n",
    "                 num_test_to_poison = 1,\n",
    "                 num_train_to_use = 10,\n",
    "                 step_size = 0.01,\n",
    "                 num_iters = 100,\n",
    "                 bounding_box_radius = 0.05,\n",
    "                 bottleneck_layer = -1\n",
    "                ):\n",
    "\n",
    "        #Dataset, model etc.\n",
    "        self.dataset = dataset\n",
    "        self.model = model\n",
    "        self.model_weights_path = model_weights_path\n",
    "        self.bottleneck_features_path = bottleneck_features_path\n",
    "        if reduced_train_size == None:\n",
    "            self.reduced_size = len(dataset[0])\n",
    "        else:\n",
    "            self.reduced_size = reduced_train_size\n",
    "\n",
    "        #Attack parameters\n",
    "        self.num_test_to_poison = num_test_to_poison\n",
    "        self.num_train_to_use = num_train_to_use\n",
    "        self.step_size = step_size\n",
    "        self.num_iters = num_iters\n",
    "        self.bounding_box_radius = bounding_box_radius\n",
    "        self.bottleneck_layer = bottleneck_layer\n",
    "\n",
    "        #Tensorflow session\n",
    "        self.sess = K.get_session()\n",
    "\n",
    "\n",
    "    def poison_dataset(self):\n",
    "        \"\"\"\n",
    "        Completes the influence poisoning attack on self.model\n",
    "        trained on self.dataset for the first self.num_test_to_poison\n",
    "        correctly classified points in the test set. Each targeted poisoning attack\n",
    "        is allowed to change self.num_train_to_use examples in the train set.\n",
    "\n",
    "        Returns:\n",
    "            Poisoned X_points\n",
    "            Predictions after poisoning\n",
    "            Confidences before poisoning\n",
    "            Confidences after poisoning\n",
    "        \"\"\"\n",
    "        x_train, y_train, x_test, y_test = self.dataset\n",
    "\n",
    "        #Train the model\n",
    "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        if self.model_weights_path == None:\n",
    "            print('Training the model')\n",
    "            self.model.fit(x_train, y_train, epochs=5)\n",
    "            v = self.model.evaluate(x_test, y_test)\n",
    "            print(v)\n",
    "        else:\n",
    "            self.model.load_weights(self.model_weights_path)\n",
    "\n",
    "        #Compute Bottleneck features: Note that we use the full train set to compute the bottleneck features\n",
    "        train_bottleneck_features = None\n",
    "        test_bottleneck_features = None\n",
    "\n",
    "        #Reduce train set size before training top model\n",
    "        x_train = x_train[:self.reduced_size]\n",
    "        y_train = y_train[:self.reduced_size]\n",
    "\n",
    "        #TODO: Will have to make the indexing here more generic for\n",
    "        #other models\n",
    "        if self.bottleneck_features_path == None:\n",
    "            print(\"COMPUTING TRAIN BOTTLENECK FEATURES\")\n",
    "            train_bottleneck_features = []\n",
    "            for k in range(10):\n",
    "                print(\"ITER \", k)\n",
    "                bottleneck_features = compute_bottleneck_features(self.model, sess, x_train[1000*k:1000*(k+1)], -1)\n",
    "                train_bottleneck_features.append(bottleneck_features)\n",
    "            train_bottleneck_features = np.vstack(train_bottleneck_features)\n",
    "\n",
    "            print(\"COMPUTING TEST BOTTLENECK FEATURES\")\n",
    "            test_bottleneck_features = compute_bottleneck_features(self.model, sess, x_test, -1)\n",
    "\n",
    "        else:\n",
    "            train_path = os.path.join(self.bottleneck_features_path, 'train_bottleneck_features.npy')\n",
    "            test_path = os.path.join(self.bottleneck_features_path, 'test_bottleneck_features.npy')\n",
    "            train_bottleneck_features = np.load(train_path)[:self.reduced_size]\n",
    "            test_bottleneck_features = np.load(test_path)\n",
    "\n",
    "        #Top model stuff: \n",
    "        lamb = 1\n",
    "        top_model = construct_top_model(512, 1, \"binary_crossentropy\", True, lamb)\n",
    "        train_top_model(top_model, train_bottleneck_features, y_train, lamb)\n",
    "        sync_top_model_to_full_model(top_model, self.model)\n",
    "\n",
    "        #Correct indices\n",
    "        preds = top_model.predict(test_bottleneck_features)\n",
    "        rounded_preds = np.round(preds)\n",
    "        correct_indices = np.where(np.logical_and((rounded_preds.flatten() == y_test), (y_test == 0), (preds.flatten() > 0.25)))[0]\n",
    "\n",
    "        confidences_before = []\n",
    "        confidences_after = []\n",
    "\n",
    "        #Finally actually perform the poisoning for each model\n",
    "        for idx, test_index_to_flip in enumerate(correct_indices[0:self.num_test_to_poison]):\n",
    "            z_bottleneck_test = [(test_bottleneck_features[test_index_to_flip], y_test[test_index_to_flip])]\n",
    "\n",
    "            confidence_before = top_model.predict(np.array([z[0] for z in z_bottleneck_test]))\n",
    "            confidences_before.append(confidence_before)\n",
    "\n",
    "            #Sort the train indices according to influence scores\n",
    "            grad_norms = grad_influence_wrt_input(self.model, self.sess, z_bottleneck_test, x_train, train_bottleneck_features, y_train, lamb, print_every=500)\n",
    "            sorted_indices = list(reversed(np.argsort(grad_norms)))\n",
    "\n",
    "            _ , confidence_after = data_poisoning_attack(self.model, self.sess, z_bottleneck_test, x_train, train_bottleneck_features, y_train, sorted_indices[:self.num_train_to_use], lamb, self.step_size, self.num_iters, self.bounding_box_radius, self.bottleneck_layer)\n",
    "            confidences_after.append(confidences_after)\n",
    "\n",
    "        return confidences_before, confidences_after\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x1296e75c0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPUTING TRAIN BOTTLENECK FEATURES\n",
      "ITER  0\n",
      "ITER  1\n",
      "ITER  2\n",
      "ITER  3\n",
      "ITER  4\n",
      "ITER  5\n",
      "ITER  6\n",
      "ITER  7\n",
      "ITER  8\n",
      "ITER  9\n",
      "COMPUTING TEST BOTTLENECK FEATURES\n",
      "COMPUTING GRAD INFLUENCE FOR  0\n",
      "COMPUTING GRAD INFLUENCE FOR  500\n",
      "COMPUTING GRAD INFLUENCE FOR  1000\n",
      "ATTACK ITER:  0\n",
      "[[0.34641555]]\n",
      "ATTACK ITER:  1\n",
      "[[0.34759334]]\n",
      "ATTACK ITER:  2\n",
      "[[0.3337822]]\n",
      "ATTACK ITER:  3\n",
      "[[0.34016588]]\n",
      "ATTACK ITER:  4\n",
      "[[0.34302163]]\n",
      "ATTACK ITER:  5\n",
      "[[0.34359157]]\n",
      "ATTACK ITER:  6\n",
      "[[0.35271055]]\n",
      "ATTACK ITER:  7\n",
      "[[0.34689674]]\n",
      "ATTACK ITER:  8\n",
      "[[0.3561743]]\n",
      "ATTACK ITER:  9\n",
      "[[0.34869346]]\n",
      "ATTACK ITER:  10\n",
      "[[0.35529006]]\n",
      "ATTACK ITER:  11\n",
      "[[0.3476985]]\n",
      "ATTACK ITER:  12\n",
      "[[0.35535482]]\n",
      "ATTACK ITER:  13\n",
      "[[0.34862027]]\n",
      "ATTACK ITER:  14\n",
      "[[0.35355502]]\n",
      "ATTACK ITER:  15\n",
      "[[0.3540961]]\n",
      "ATTACK ITER:  16\n",
      "[[0.36249328]]\n",
      "ATTACK ITER:  17\n",
      "[[0.35975268]]\n",
      "ATTACK ITER:  18\n",
      "[[0.35459235]]\n",
      "ATTACK ITER:  19\n",
      "[[0.360407]]\n",
      "ATTACK ITER:  20\n",
      "[[0.3625294]]\n",
      "ATTACK ITER:  21\n",
      "[[0.36611414]]\n",
      "ATTACK ITER:  22\n",
      "[[0.35401076]]\n",
      "ATTACK ITER:  23\n",
      "[[0.36495882]]\n",
      "ATTACK ITER:  24\n",
      "[[0.36328274]]\n",
      "ATTACK ITER:  25\n",
      "[[0.3714575]]\n",
      "ATTACK ITER:  26\n",
      "[[0.3680345]]\n",
      "ATTACK ITER:  27\n",
      "[[0.3748742]]\n",
      "ATTACK ITER:  28\n",
      "[[0.37522942]]\n",
      "ATTACK ITER:  29\n",
      "[[0.35894918]]\n",
      "ATTACK ITER:  30\n",
      "[[0.36849263]]\n",
      "ATTACK ITER:  31\n",
      "[[0.3718129]]\n",
      "ATTACK ITER:  32\n",
      "[[0.36524925]]\n",
      "ATTACK ITER:  33\n",
      "[[0.37151387]]\n",
      "ATTACK ITER:  34\n",
      "[[0.37531683]]\n",
      "ATTACK ITER:  35\n",
      "[[0.3660584]]\n",
      "ATTACK ITER:  36\n",
      "[[0.37745318]]\n",
      "ATTACK ITER:  37\n",
      "[[0.38079405]]\n",
      "ATTACK ITER:  38\n",
      "[[0.3656984]]\n",
      "ATTACK ITER:  39\n",
      "[[0.37442464]]\n",
      "ATTACK ITER:  40\n",
      "[[0.38521302]]\n",
      "ATTACK ITER:  41\n",
      "[[0.37343737]]\n",
      "ATTACK ITER:  42\n",
      "[[0.3892127]]\n",
      "ATTACK ITER:  43\n",
      "[[0.37471643]]\n",
      "ATTACK ITER:  44\n",
      "[[0.38344255]]\n",
      "ATTACK ITER:  45\n",
      "[[0.3815361]]\n",
      "ATTACK ITER:  46\n",
      "[[0.3819092]]\n",
      "ATTACK ITER:  47\n",
      "[[0.382799]]\n",
      "ATTACK ITER:  48\n",
      "[[0.38534343]]\n",
      "ATTACK ITER:  49\n",
      "[[0.3917172]]\n",
      "ATTACK ITER:  50\n",
      "[[0.38357854]]\n",
      "ATTACK ITER:  51\n",
      "[[0.3812084]]\n",
      "ATTACK ITER:  52\n",
      "[[0.37901726]]\n",
      "ATTACK ITER:  53\n",
      "[[0.3821885]]\n",
      "ATTACK ITER:  54\n",
      "[[0.388974]]\n",
      "ATTACK ITER:  55\n",
      "[[0.3974552]]\n",
      "ATTACK ITER:  56\n",
      "[[0.4052909]]\n",
      "ATTACK ITER:  57\n",
      "[[0.38398835]]\n",
      "ATTACK ITER:  58\n",
      "[[0.38774934]]\n",
      "ATTACK ITER:  59\n",
      "[[0.39422646]]\n",
      "ATTACK ITER:  60\n",
      "[[0.40272248]]\n",
      "ATTACK ITER:  61\n",
      "[[0.3969643]]\n",
      "ATTACK ITER:  62\n",
      "[[0.40228316]]\n",
      "ATTACK ITER:  63\n",
      "[[0.40651837]]\n",
      "ATTACK ITER:  64\n",
      "[[0.4053734]]\n",
      "ATTACK ITER:  65\n",
      "[[0.3990511]]\n",
      "ATTACK ITER:  66\n",
      "[[0.41485438]]\n",
      "ATTACK ITER:  67\n",
      "[[0.4095916]]\n",
      "ATTACK ITER:  68\n",
      "[[0.41446027]]\n",
      "ATTACK ITER:  69\n",
      "[[0.40022245]]\n",
      "ATTACK ITER:  70\n",
      "[[0.41468745]]\n",
      "ATTACK ITER:  71\n",
      "[[0.39606002]]\n",
      "ATTACK ITER:  72\n",
      "[[0.40811238]]\n",
      "ATTACK ITER:  73\n",
      "[[0.41170427]]\n",
      "ATTACK ITER:  74\n",
      "[[0.40276244]]\n",
      "ATTACK ITER:  75\n",
      "[[0.41365334]]\n",
      "ATTACK ITER:  76\n",
      "[[0.4097864]]\n",
      "ATTACK ITER:  77\n",
      "[[0.41983443]]\n",
      "ATTACK ITER:  78\n",
      "[[0.40979242]]\n",
      "ATTACK ITER:  79\n",
      "[[0.42029005]]\n",
      "ATTACK ITER:  80\n",
      "[[0.41046402]]\n",
      "ATTACK ITER:  81\n",
      "[[0.4063919]]\n",
      "ATTACK ITER:  82\n",
      "[[0.40805593]]\n",
      "ATTACK ITER:  83\n",
      "[[0.41478574]]\n",
      "ATTACK ITER:  84\n",
      "[[0.4211525]]\n",
      "ATTACK ITER:  85\n",
      "[[0.4196456]]\n",
      "ATTACK ITER:  86\n",
      "[[0.4157958]]\n",
      "ATTACK ITER:  87\n",
      "[[0.42391688]]\n",
      "ATTACK ITER:  88\n",
      "[[0.41962856]]\n",
      "ATTACK ITER:  89\n",
      "[[0.41188952]]\n",
      "ATTACK ITER:  90\n",
      "[[0.41156697]]\n",
      "ATTACK ITER:  91\n",
      "[[0.44081292]]\n",
      "ATTACK ITER:  92\n",
      "[[0.43123227]]\n",
      "ATTACK ITER:  93\n",
      "[[0.42522365]]\n",
      "ATTACK ITER:  94\n",
      "[[0.43335056]]\n",
      "ATTACK ITER:  95\n",
      "[[0.41676155]]\n",
      "ATTACK ITER:  96\n",
      "[[0.41354704]]\n",
      "ATTACK ITER:  97\n",
      "[[0.43905213]]\n",
      "ATTACK ITER:  98\n",
      "[[0.4383887]]\n",
      "ATTACK ITER:  99\n",
      "[[0.43283665]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sess = K.get_session()\n",
    "K.set_learning_phase(1)\n",
    "\n",
    "do_06_model = InfluencePoisoner(ship_bike_dataset, model,\n",
    "                            model_weights_path =\"models/imagenet_ship_bike_squeezenet_do06.h5\",\n",
    "                            num_train_to_use = 50,\n",
    "                            bounding_box_radius = 2,\n",
    "                            step_size = 0.1)\n",
    "results = do_06_model.poison_dataset()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([[0.34473616]], dtype=float32)], [[...]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
